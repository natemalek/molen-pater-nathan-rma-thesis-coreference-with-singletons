{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cort.core.corpora import Corpus\n",
    "import os\n",
    "from docopt import docopt\n",
    "import sys\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from utils import map_values\n",
    "import codecs\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(inp_dir):\n",
    "    mentions, tokens, names = [], [], []\n",
    "    for fname in os.listdir(inp_dir):\n",
    "        if fname.endswith('_gold_conll'):\n",
    "            path = os.path.join(inp_dir, fname)\n",
    "            try:\n",
    "                with codecs.open(path, 'r', 'utf-8') as f:\n",
    "                    corpus = Corpus.from_file('', f)\n",
    "            except KeyError:\n",
    "                # https://github.com/dmcc/PyStanfordDependencies/issues/24\n",
    "                sys.stderr.write(\"Ignored due to parsing error: %s\\n\" %path)\n",
    "            for doc in corpus:\n",
    "                if not doc.annotated_mentions:\n",
    "                    sys.stderr.write(\"Document doesn't contain any mention: %s in %s\\n\" %(doc.identifier, path))\n",
    "                else:\n",
    "                    my_mentions, my_tokens, my_names = read_document(doc)\n",
    "                    mentions.extend(my_mentions)\n",
    "                    tokens.extend(my_tokens)\n",
    "                    names.extend(my_names)\n",
    "    return mentions, tokens, names\n",
    "\n",
    "\n",
    "def read_document(doc):\n",
    "    mentions = [m for m in doc.annotated_mentions]\n",
    "    tokens = [doc.tokens[i]\n",
    "              for m in mentions\n",
    "              for i in range(m.span.begin, m.span.end+1)]\n",
    "    names = [doc.tokens[i] \n",
    "             for m in mentions\n",
    "             for i in range(m.span.begin, m.span.end+1)\n",
    "             if doc.pos[i] in ['NNP', 'NNPS']]\n",
    "    return mentions, tokens, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Document doesn't contain any mention: (bn/voa/00/voa_0043); part 000 in ../data/conll-2012-flat/train/bn_voa_0043.v4_gold_conll\n",
      "Document doesn't contain any mention: (nw/wsj/10/wsj_1088); part 000 in ../data/conll-2012-flat/train/nw_wsj_1088.v4_gold_conll\n",
      "Document doesn't contain any mention: (nw/wsj/13/wsj_1384); part 000 in ../data/conll-2012-flat/train/nw_wsj_1384.v4_gold_conll\n",
      "Document doesn't contain any mention: (bc/cnn/00/cnn_0001); part 009 in ../data/conll-2012-flat/train/bc_cnn_0001.v4_gold_conll\n",
      "Document doesn't contain any mention: (nw/xinhua/02/chtb_0205); part 000 in ../data/conll-2012-flat/train/nw_chtb_0205.v4_gold_conll\n",
      "Ignored due to parsing error: ../data/conll-2012-flat/train/tc_ch_0005.v4_gold_conll\n",
      "Document doesn't contain any mention: (bn/voa/00/voa_0017); part 000 in ../data/conll-2012-flat/train/bn_voa_0017.v4_gold_conll\n",
      "Document doesn't contain any mention: (bn/abc/00/abc_0024); part 000 in ../data/conll-2012-flat/train/bn_abc_0024.v4_gold_conll\n",
      "Document doesn't contain any mention: (bn/abc/00/abc_0054); part 000 in ../data/conll-2012-flat/train/bn_abc_0054.v4_gold_conll\n",
      "Document doesn't contain any mention: (nw/xinhua/01/chtb_0175); part 000 in ../data/conll-2012-flat/train/nw_chtb_0175.v4_gold_conll\n",
      "Document doesn't contain any mention: (nw/wsj/13/wsj_1342); part 000 in ../data/conll-2012-flat/train/nw_wsj_1342.v4_gold_conll\n",
      "Document doesn't contain any mention: (nw/wsj/14/wsj_1408); part 000 in ../data/conll-2012-flat/train/nw_wsj_1408.v4_gold_conll\n",
      "Document doesn't contain any mention: (bn/pri/00/pri_0097); part 000 in ../data/conll-2012-flat/train/bn_pri_0097.v4_gold_conll\n",
      "Document doesn't contain any mention: (bn/voa/00/voa_0065); part 000 in ../data/conll-2012-flat/train/bn_voa_0065.v4_gold_conll\n",
      "Document doesn't contain any mention: (nw/xinhua/01/chtb_0195); part 000 in ../data/conll-2012-flat/train/nw_chtb_0195.v4_gold_conll\n",
      "Ignored due to parsing error: ../data/conll-2012-flat/train/tc_ch_0024.v4_gold_conll\n",
      "Document doesn't contain any mention: (nw/wsj/10/wsj_1067); part 000 in ../data/conll-2012-flat/train/nw_wsj_1067.v4_gold_conll\n",
      "Document doesn't contain any mention: (bn/abc/00/abc_0008); part 000 in ../data/conll-2012-flat/train/bn_abc_0008.v4_gold_conll\n",
      "Document doesn't contain any mention: (bn/voa/01/voa_0145); part 000 in ../data/conll-2012-flat/train/bn_voa_0145.v4_gold_conll\n",
      "Document doesn't contain any mention: (nw/wsj/21/wsj_2122); part 000 in ../data/conll-2012-flat/train/nw_wsj_2122.v4_gold_conll\n",
      "Document doesn't contain any mention: (bn/voa/00/voa_0006); part 000 in ../data/conll-2012-flat/train/bn_voa_0006.v4_gold_conll\n",
      "Document doesn't contain any mention: (bn/cnn/01/cnn_0143); part 000 in ../data/conll-2012-flat/train/bn_cnn_0143.v4_gold_conll\n",
      "Ignored due to parsing error: ../data/conll-2012-flat/train/bn_cnn_0432.v4_gold_conll\n",
      "Document doesn't contain any mention: (bn/voa/01/voa_0158); part 000 in ../data/conll-2012-flat/train/bn_voa_0158.v4_gold_conll\n",
      "Document doesn't contain any mention: (bn/voa/00/voa_0045); part 000 in ../data/conll-2012-flat/train/bn_voa_0045.v4_gold_conll\n",
      "Ignored due to parsing error: ../data/conll-2012-flat/train/tc_ch_0004.v4_gold_conll\n",
      "Document doesn't contain any mention: (nw/wsj/14/wsj_1406); part 000 in ../data/conll-2012-flat/train/nw_wsj_1406.v4_gold_conll\n",
      "Document doesn't contain any mention: (bn/voa/02/voa_0223); part 000 in ../data/conll-2012-flat/train/bn_voa_0223.v4_gold_conll\n",
      "Document doesn't contain any mention: (bn/nbc/00/nbc_0038); part 000 in ../data/conll-2012-flat/train/bn_nbc_0038.v4_gold_conll\n",
      "Document doesn't contain any mention: (nw/wsj/14/wsj_1486); part 000 in ../data/conll-2012-flat/train/nw_wsj_1486.v4_gold_conll\n",
      "Ignored due to parsing error: ../data/conll-2012-flat/train/bc_msnbc_0001.v4_gold_conll\n",
      "Document doesn't contain any mention: (bn/abc/00/abc_0012); part 000 in ../data/conll-2012-flat/train/bn_abc_0012.v4_gold_conll\n"
     ]
    }
   ],
   "source": [
    "inp_dir = '../data/conll-2012-flat'\n",
    "train_mentions, train_tokens, train_names = read_dataset(os.path.join(inp_dir, 'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Document doesn't contain any mention: (bn/cnn/02/cnn_0240); part 000\n"
     ]
    }
   ],
   "source": [
    "_, dev_tokens, dev_names = read_dataset(os.path.join(inp_dir, 'dev'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_numeric(token):\n",
    "    return bool(re.match(r'(mid-|\\'|\")?(\\+|-)?[\\d\\.,]*\\d+(/[\\d\\.,]*\\d+)?(th|st|nd|rd|s)?$', token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(tokens, names):\n",
    "    tokens = [t.lower() for t in tokens]\n",
    "    names = [n.lower() for n in names]\n",
    "    \n",
    "    numbers = [t for t in tokens if is_numeric(t)]\n",
    "    uniq_numbers = set(numbers)\n",
    "    uniq_names = set(names)\n",
    "    common = [t for t in tokens if not (t in uniq_numbers or t in uniq_names)]\n",
    "    uniq_common = set(common)\n",
    "    unique_tokens = set(tokens)\n",
    "    assert uniq_numbers.union(uniq_names).union(uniq_common) == unique_tokens\n",
    "    \n",
    "    stats = {\n",
    "        'num_numbers': len(numbers),\n",
    "        'num_names': len(names),\n",
    "        'num_commons': len(common),\n",
    "        'num_total': len(tokens),\n",
    "        'pct_numbers': len(numbers) / len(tokens),\n",
    "        'pct_names': len(names) / len(tokens),\n",
    "        'pct_commons': len(common) / len(tokens),\n",
    "        \n",
    "        'num_unique_numbers': len(uniq_numbers),\n",
    "        'num_unique_common': len(uniq_common),\n",
    "        'num_unique_names': len(uniq_names),\n",
    "        'num_unique_total': len(unique_tokens),\n",
    "        'pct_unique_numbers': len(uniq_numbers) / len(unique_tokens),\n",
    "        'pct_unique_common': len(uniq_common) / len(unique_tokens),\n",
    "        'pct_unique_names': len(uniq_names) / len(unique_tokens),\n",
    "    }\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_stats = compute_stats(dev_tokens, dev_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_numbers': 400,\n",
       " 'num_names': 10586,\n",
       " 'num_commons': 24971,\n",
       " 'num_total': 45397,\n",
       " 'pct_numbers': 0.008811154922131418,\n",
       " 'pct_names': 0.233187215014208,\n",
       " 'pct_commons': 0.5500583739013591,\n",
       " 'num_unique_numbers': 150,\n",
       " 'num_unique_common': 3447,\n",
       " 'num_unique_names': 2056,\n",
       " 'num_unique_total': 5653,\n",
       " 'pct_unique_numbers': 0.02653458340704051,\n",
       " 'pct_unique_common': 0.6097647266937909,\n",
       " 'pct_unique_names': 0.3637006898991686}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/pct_unique_names.tex', 'w') as f:\n",
    "    f.write('%.0f\\\\%%' %(100*dev_stats['pct_unique_names']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/pct_names.tex', 'w') as f:\n",
    "    f.write('%.0f\\\\%%' %(100*dev_stats['pct_names']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_train_names = set(train_names)\n",
    "uniq_train_tokens = set(train_tokens)\n",
    "dev_names_in_train = [n for n in dev_names if n in uniq_train_names]\n",
    "dev_tokens_in_train = [n for n in dev_tokens if n in uniq_train_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8286416021160022"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_names_in_train) / len(dev_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9318457166773135"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_tokens_in_train) / len(dev_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Taiwan', 241),\n",
       " ('Mr.', 200),\n",
       " ('China', 177),\n",
       " ('God', 165),\n",
       " ('Hong', 143),\n",
       " ('Kong', 143),\n",
       " ('Jesus', 136),\n",
       " ('President', 115),\n",
       " ('Bush', 92),\n",
       " ('U.S.', 83),\n",
       " ('New', 82),\n",
       " ('Ye', 60),\n",
       " ('Iraq', 59),\n",
       " ('News', 57),\n",
       " ('Sony', 56),\n",
       " ('York', 53),\n",
       " ('Chen', 52),\n",
       " ('Lord', 50),\n",
       " ('NBC', 48),\n",
       " ('Court', 46),\n",
       " ('Florida', 44),\n",
       " ('Israel', 44),\n",
       " ('Peter', 43),\n",
       " ('Gore', 43),\n",
       " ('Clinton', 41),\n",
       " ('Congress', 39),\n",
       " ('Milosevic', 38),\n",
       " ('Christ', 36),\n",
       " ('Japan', 36),\n",
       " ('Association', 36),\n",
       " ('Qingqing', 36),\n",
       " ('Washington', 35),\n",
       " ('Bank', 35),\n",
       " ('Supreme', 35),\n",
       " ('Cross', 35),\n",
       " ('United', 34),\n",
       " ('World', 34),\n",
       " ('Mao', 34),\n",
       " ('Cole', 34),\n",
       " ('Straits', 34),\n",
       " ('Beijing', 33),\n",
       " ('Red', 33),\n",
       " ('US', 32),\n",
       " ('ANC', 31),\n",
       " ('Saddam', 30),\n",
       " ('West', 30),\n",
       " ('Kostunica', 30),\n",
       " ('Father', 29),\n",
       " ('Friday', 29),\n",
       " ('Michael', 28),\n",
       " ('States', 27),\n",
       " ('John', 27),\n",
       " ('Inc.', 27),\n",
       " ('Chinese', 26),\n",
       " ('Europe', 26),\n",
       " ('Senate', 26),\n",
       " ('Justin', 26),\n",
       " ('Jackson', 25),\n",
       " ('South', 25),\n",
       " ('Secretary', 24),\n",
       " ('Serbia', 24),\n",
       " ('Keating', 24),\n",
       " ('Corp.', 23),\n",
       " ('ROC', 23),\n",
       " ('Paul', 23),\n",
       " ('Sen.', 22),\n",
       " ('War', 22),\n",
       " ('Zedong', 22),\n",
       " ('Chairman', 22),\n",
       " ('Gaza', 22),\n",
       " ('Martha', 22),\n",
       " ('Farmers', 22),\n",
       " ('George', 21),\n",
       " ('VOA', 21),\n",
       " ('First', 21),\n",
       " ('Korea', 21),\n",
       " ('American', 21),\n",
       " ('Al', 21),\n",
       " ('September', 20),\n",
       " ('Zhuhai', 20),\n",
       " ('Yugoslavia', 20),\n",
       " ('Anhui', 20),\n",
       " ('Minister', 19),\n",
       " ('Brady', 19),\n",
       " ('David', 18),\n",
       " ('General', 18),\n",
       " ('Cornelius', 18),\n",
       " ('Yemen', 18),\n",
       " ('USS', 18),\n",
       " ('Radio', 18),\n",
       " ('Party', 18),\n",
       " ('IRS', 18),\n",
       " ('Macao', 18),\n",
       " ('California', 17),\n",
       " ('Department', 17),\n",
       " ('heaven', 17),\n",
       " ('Group', 17),\n",
       " ('Belgrade', 17),\n",
       " ('James', 17),\n",
       " ('August', 17)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(dev_names_in_train).most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset2(inp_dir):\n",
    "    for fname in os.listdir(inp_dir):\n",
    "        if fname.endswith('_gold_conll'):\n",
    "            path = os.path.join(inp_dir, fname)\n",
    "            try:\n",
    "                with codecs.open(path, 'r', 'utf-8') as f:\n",
    "                    corpus = Corpus.from_file('', f)\n",
    "            except KeyError:\n",
    "                # https://github.com/dmcc/PyStanfordDependencies/issues/24\n",
    "                sys.stderr.write(\"Ignored due to parsing error: %s\\n\" %path)\n",
    "            for doc in corpus:\n",
    "                for speaker in doc.speakers:\n",
    "                    yield speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = Counter(read_dataset2(os.path.join(inp_dir, 'dev')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
